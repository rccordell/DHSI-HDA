---
title: "dataframes"
author: "Ryan Cordell"
date: "1/20/2017"
output: html_document
---

For today's workshop, we're going to load in all the libraries we need right off the bat, so we don't have the confusion of last week. If you find you don't have one of these installed, then install it! Most of what we do today uses functions from the packages `tidyr` and `dplyr`, which are both included in `tidyverse`. Today I won't be putting everything in executable codeblocks. If there's no run button, remember how to run lines of code manually!

```{r}
library(tidyverse)
```

# Navigating Files in R

If you've only browsed files through a GUI you might not realize this, but your computer's directories can be invoked through paths that look much like URLs. To illustrate this, we're going to browse around in your Terminals for a few minutes before we jump back into R.

At any given time, R refers to a particular "working directory" on your hard drive. Any paths to data you construct take this working directory as their root. So if my working directory is `"Dropbox/Teaching/HDA/s17hda-github/"` then invoking `"/data/crewlists.csv"` would begin from the working directory and look for a subdirectory called `data` and then a file within that working directory. Many, many times problems importing or working with data can be tracked down to R looking in the wrong working directory. So, to check your working directory, you can run:

```{r}
getwd()
```

If the working directory is not what you want, you can set it in two ways: through the menus for Session --> Set Working Directory or through the command below. The path to the directory you want should go inside the quotation marks. Remember that you can use your tab key to help you autocomplete fields in R; that can be very useful for getting to precisely the right folder on your hard drive.

```{r}
setwd("")
```

When you construct a file path in R, your working directory can be invoked with `.` and your computers home directory can be invoked with `~`. You can also tell R Studio to look backwards in the directory structure with `..` We'll experiment with this briefly over in the console. Keep in mind too that you can browse your files in in the `Files` pane of RStudio: it's over there next to `Environment`.

# Getting Help with Functions

Here's another useful thing to know. If you want to know what a particular function does, you can access help documentation using `?` or `help()`. So if you wanted to know what the `spread` function (from the package `tidyr`) does, you could run:

?spread

*or* 

help(spread)


# Reading in Tabular Data

Depending on the structure of the data you wish to read into R, you will typically use `read.table`, `read.csv`, or `scan`. You can sometimes read data in from the web directly, as we did last week, but most often you will have data stored on your computer that you wish to bring into the R environment. Often, if there is something even slightly askew about your input data, `read.table` will fail. This may be frustrating, but this failure is  a general feature of data analysis: programs that don't receive *exactly* the input the expect will simply fail to work, usually "throwing" an error message of some sort. You may have to spend some time troubleshooting your data itself to figure out why it won't import into R.

If you have a file previously saved in the csv (comma-separated-value) format, it may be fast to read it it using the `read.csv` function. (This is simply `read.table` with a certain set of constraints.)

In the example below, you'll need to modify the path in the quotation marks to navigate the folder in your file system to where you have stored the data files for this class. 

```{r}
census <- read.csv(file = "./data/1840-census-data.csv")
```

Note: we could write out the file path in other ways, depending on precisely how you've organized things.  

# Browsing Tabular Data

If you type `View(census)` or click the table icon next to `census` in the Environment pane, you can visually browse the dataframe we just created.

When we work with dataframes, we can operate on individual columns using the `$` operator. If we type `census$Slave_Female` in the console, for instance, it would print all the values from that one column. We usually won't use this to print, however, but to select particular columns to operate on in other ways.

Let's not forget some of the basic ways of browsing data we discussed last week. Can you write code below that print the first lines of the `census` dataframe? The last? Can you print the first or last lines of specific columns in `census`?

```{r}



```

There are a few other fuctions worth knowing right off the bat. Run the code below: what does `summary` do?

```{r}
summary(census$Newspapers)
summary(census$FreeColoredPopulation)
```

## A Note about Pipes

Next week we will introduce pipes more fully, which will enable you to combine many of the functions we will learn today and write code with fewer steps. For today, however, I really want you thinking about what how each function transforms your data, so we're going to take everything one step at a time.

## Subsetting columns

This is a very wide dataframe of census data. In fact, it's a bit too wide for R studio, which will only display 100 columns in the table viewer; this table has 113 columns. For any given analysis task, we probably don't need all of the columns in such a wide dataframe. Fortunately R and the `tidyverse` packages give us lots of ways to pare down the data we're working with. 

Remember that last week we talked about changing variables. That's one way to pare down a dataset: essentially we invoke the dataframe, select only a few columns of it using the `select` function in `dplyr`, and replace the whole variable with just those selected columns. That would look like this:

```{r}
census <- select(census, QualifyingAreaName, Newspapers, Newspapers_Daily, Newspapers_Weekly, Newspapers_SemiTriWeekly, Periodicals, PrintingOffices, Binderies, NumberofPersonsEmployedinPrintingBinding)
```

Now we have only 9 variables in our dataframe, which is focused on the data recorded about newspapers and printing in the census. In this case we overwrote the whole census variable with this smaller dataframe, but we could have created a new variable focused on printing (say `censusPrinting`) and retained the larger `census` variable as well. 

If you know the data you're importing well, you can also select particular columns on import. I further truncated the columns below so you can see a difference:

```{r}
census <- read.csv(file="./data/1840-census-data.csv")[ , c("QualifyingAreaName", "Newspapers", "Newspapers_Daily", "Newspapers_Weekly", "Newspapers_SemiTriWeekly", "Periodicals", "PrintingOffices")]
```

We can also rename columns with, you guessed it, the `rename` function. That first column in `census` has an awkward name, so let's just change it:

```{r}
census <- rename(census, county = QualifyingAreaName)
```

There are also ways to subset by rows that meet particular conditions, as in:

```{r}
printCenters <- filter(census, PrintingOffices >= 5)
```

We can also add new columns with `mutate`. These new columns can include an entirely new bit of data we wish to add (this can be tricky; we can talk more about what this might mean in person) or can be derived from operations made on other columns, as in:

```{r}
census <- mutate(census, serials = Newspapers + Periodicals)
head(census$serials)
```

Can you see what happened there?

Finally (in this section), we can rearrange the dataframe. Keep in mind that `arrange` reorders the actual dataframe permanently, or as permanently as is possible in a variable. In later weeks we'll learn how to order things on the fly for particular operations without actually changing the structure of the dataframe itself. To sort by the number of serials in each county, we could write:

```{r}
census <- arrange(census, serials, Newspapers, Periodicals)
```

You only need to specify one column for `arrange` to work, but if you specify more it will use them in sequence, much as you use the letters in words in sequence when sorting into alphabetical order (e.g. first sort by `serials`, then by `Newspapers`, then by `Periodicals`). You'll note that by default `arrange` sorts in ascending order. If we wanted to instead order this dataframe to bring the most active print economies to the top, we would add `desc` to our code:  

```{r}
census <- arrange(census, desc(serials, Newspapers, Periodicals))
```

Okay: in the code block below, import the census data again (use a new variable name) and then select only 3-4 columns of interest. Then filter the dataframe by a value in one of those columns. 

```{r}



```

# Manipulating Dataframes

Above we made some relatively minor changes to a dataframe, but in the next section we'll do a bit more. As we talk about different methods for manipulating the data in dataframes, the [Data Wrangling Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) will prove very helpful. We recommend you bookmark it, at least, and perhaps print it into a breviary you carry with you at all times for your R devotions. 

## Separate

Let's start with `separate`, which will allow us to do something kind of like RegEx, but simpler, for colums we want to break apart that use a very consistent separator. The newly-renamed `county` column, for instance, actually includes both the county and the state, and since they are consistently divided by a comma and space, we can use the fuction below to separate them into two columns:

```{r}
census <- separate(census, county, into = c("county", "state"), sep = "\\, ")
```

That threw a few errors, though `tidyr` made the separation anyway. If you wanted to investigate one of those problematic observations, you could type in the console `census[1259,]` (or sustitute any of the other rows for 1259). This is another way of selecting particular rows. In this case we're not entering anything after the comma because we want to see all the columns, but you could instead type `census[1259,1:2]` to see row 1259, columns 1-2.

## Gather

For these next functions we're going to reimport our census data but select a different set of columns: those describing the racial/ethnic/gender/age identification of the populations in each county. The current format of this data is "wide," meaning there are many columns of variables. For certain kinds of analyses, these column names are themselves variables, representing the identities of citizens, at least insofar as the census taker appraised them. We might want to `gather` our data into a "long" format, which means there will be many more rows but fewer columns, which will prove useful for certain kinds of analyses. Let's run the code below and talk through it together. If you want to see what each line is doing, run them using ctl-enter rather than the run button.

```{r}
census <- read.csv(file = "./data/1840-census-data.csv")
census <- select(census, 1,6:81)
census <- rename(census, county = QualifyingAreaName)
census_long <- gather(census, "identification", "count", 2:77)
census_long <- separate(census_long, county, into = c("county", "state"), sep = "\\, ")
census_long <- na.omit(census_long)
```

## Group_by

Why would we do this? Well, for one we could now use the `group_by()` function on our `identification` column to group all observations of the same identification, and then perform operations on those groups. 

```{r}
census_long <- group_by(census_long, identification)
census_ids <- summarize(census_long, total_ids = sum(count))
```

That's possibly interesting, but maybe we want to group by identification and then by state, so we can see how these categories break down by state. Fortunately we now have a state column, so we can do this:

```{r}
census_long <- group_by(census_long, state, identification)
census_ids <- summarize(census_long, total_ids = sum(count))
```

## Spread

Spread, as you might imagine, does just the opposite of gather. It takes long data and makes it wide. So we can run the following to reshape our `census_long` dataframe into something very like the wide dataframe with which we began.

```{r}
census_wide <- spread(census_long, identification, count)
View(census_wide)
```

# Exercises

1. Create a new column that shows the ratio of `FreeColoredPopulation` to `SlavePopulation` in each county. You may need to repeat some of the import steps above, and you can use a new variable if you wish. 
2. Create a "long" dataframe with columns for "publication_type" (e.g. "Newspaper") and "count". 

```{r}
census <- read.csv(file="./data/1840-census-data.csv")[ , c("QualifyingAreaName", "Newspapers", "Newspapers_Daily", "Newspapers_Weekly", "Newspapers_SemiTriWeekly", "Periodicals", "PrintingOffices")]
census <- rename(census, county = QualifyingAreaName)
census_long <- gather(census, "publication_type", "count", 2:7)
census_long <- separate(census_long, county, into = c("county", "state"), sep = "\\, ")
census_long <- na.omit(census_long)
```

3. Determine the state (not the county!) with the highest population of literate whites over 20 years old, then determine the state with the highest ratio of literate whites to general population.

```{r}
census <- read_csv(file="./data/1840-census-data.csv")
census <- rename(census, county = QualifyingAreaName)
census <- separate(census, county, into = c("county", "state"), sep = "\\, ")
census <- group_by(census, state)
literate <- summarize(census, totalLit = sum(LiterateWhiteAge20andOver))
literate <- arrange(literate, desc(totalLit))

```

```{r}
census <- read_csv(file="./data/1840-census-data.csv")
census <- rename(census, county = QualifyingAreaName)
census <- separate(census, county, into = c("county", "state"), sep = "\\, ")
census <- group_by(census, state)
literate <- summarize(census, totalLit = sum(LiterateWhiteAge20andOver) / sum(TotalPopulation))
literate <- arrange(literate, desc(totalLit))

```


4. Read in `booktitles-sub.tsv`. You won't be able to use `read.csv` for this tsv file. See if you can figure out how to import a TSV using [Stack Overflow](http://stackoverflow.com/) or [RSeek](http://rseek.org/). Within this dataset, which year saw the most publications? What author was most prolific?
5. Reach goal: What is the oldest children's book in `booktitles-sub.tsv`?